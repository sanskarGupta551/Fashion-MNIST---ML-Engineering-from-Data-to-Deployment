{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e3219d",
   "metadata": {},
   "source": [
    "# **Fashion MNIST: Feature Engineering**\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928f3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:24:12.699821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745850252.712526   34706 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745850252.716240   34706 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745850252.727362   34706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745850252.727381   34706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745850252.727382   34706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745850252.727383   34706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 14:24:12.731301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf005d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 2. Define class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a5aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Combine data for processing\n",
    "x_all = np.concatenate([x_train, x_test])\n",
    "y_all = np.concatenate([y_train, y_test])\n",
    "split_labels = ['train'] * len(x_train) + ['test'] * len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46b988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate PCA components (for dimension reduction)\n",
    "# Flatten images for PCA\n",
    "x_flat = x_all.reshape(x_all.shape[0], -1)\n",
    "\n",
    "# Fit PCA on a subset to save memory\n",
    "sample_size = 10000\n",
    "random_indices = np.random.choice(len(x_flat), sample_size, replace=False)\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(x_flat[random_indices])\n",
    "\n",
    "# Transform all data\n",
    "pca_results = pca.transform(x_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226da4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Feature extraction function\n",
    "def extract_features(image):\n",
    "    # Basic statistics\n",
    "    mean_brightness = np.mean(image)\n",
    "    std_deviation = np.std(image)\n",
    "    \n",
    "    # Edge detection\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    edge_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    edge_density = np.mean(edge_magnitude)\n",
    "    \n",
    "    # Histogram features (5 bins)\n",
    "    hist, _ = np.histogram(image, bins=5, range=(0, 255))\n",
    "    hist = hist / np.sum(hist)  # Normalize\n",
    "    \n",
    "    return {\n",
    "        'mean_brightness': mean_brightness,\n",
    "        'std_deviation': std_deviation,\n",
    "        'edge_density': edge_density,\n",
    "        'hist_bin1': hist[0],\n",
    "        'hist_bin2': hist[1],\n",
    "        'hist_bin3': hist[2],\n",
    "        'hist_bin4': hist[3],\n",
    "        'hist_bin5': hist[4]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80694e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/70000 images\n",
      "Processed 10000/70000 images\n",
      "Processed 20000/70000 images\n",
      "Processed 30000/70000 images\n",
      "Processed 40000/70000 images\n",
      "Processed 50000/70000 images\n",
      "Processed 60000/70000 images\n"
     ]
    }
   ],
   "source": [
    "# 6. Process all images\n",
    "image_features = []\n",
    "metadata_features = []\n",
    "\n",
    "for i in range(len(x_all)):\n",
    "    # Generate unique image ID\n",
    "    image_id = f\"img_{i}\"\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(x_all[i])\n",
    "    \n",
    "    # Image features\n",
    "    image_features.append({\n",
    "        'image_id': image_id,\n",
    "        'mean_brightness': features['mean_brightness'],\n",
    "        'std_deviation': features['std_deviation'],\n",
    "        'edge_density': features['edge_density'],\n",
    "        'pca_component_1': pca_results[i][0],\n",
    "        'pca_component_2': pca_results[i][1],\n",
    "        'pca_component_3': pca_results[i][2],\n",
    "        'pca_component_4': pca_results[i][3],\n",
    "        'pca_component_5': pca_results[i][4],\n",
    "        'hist_bin1': features['hist_bin1'],\n",
    "        'hist_bin2': features['hist_bin2'],\n",
    "        'hist_bin3': features['hist_bin3'],\n",
    "        'hist_bin4': features['hist_bin4'],\n",
    "        'hist_bin5': features['hist_bin5']\n",
    "    })\n",
    "\n",
    "    \n",
    "    # Metadata features\n",
    "    metadata_features.append({\n",
    "        'image_id': image_id,\n",
    "        'class_id': int(y_all[i]),\n",
    "        'class_name': class_names[y_all[i]],\n",
    "        'data_split': split_labels[i]\n",
    "    })\n",
    "    \n",
    "    # Show progress\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Processed {i}/{len(x_all)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce805a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Convert to dataframes\n",
    "image_features_df = pd.DataFrame(image_features)\n",
    "metadata_features_df = pd.DataFrame(metadata_features)\n",
    "\n",
    "# 8. Save to CSV\n",
    "image_features_df.to_csv('./features/image_features.csv', index=False)\n",
    "metadata_features_df.to_csv('./features/metadata_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e331b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Features (first 5 rows):\n",
      "  image_id  mean_brightness  std_deviation  edge_density  pca_component_1  \\\n",
      "0    img_0        97.253827     101.792346    192.181315      -133.960372   \n",
      "1    img_1       107.905612     100.831448    225.351588      1420.510590   \n",
      "2    img_2        36.558673      49.698752     83.301051      -692.044930   \n",
      "3    img_3        59.501276      64.849295    136.712344        60.543575   \n",
      "4    img_4        78.044643     103.843248    190.411598       838.742679   \n",
      "\n",
      "   pca_component_2  pca_component_3  pca_component_4  pca_component_5  \\\n",
      "0      1634.674432     -1180.050450      -351.047373         9.991461   \n",
      "1      -425.358405      -224.046959      -361.054253       290.012937   \n",
      "2     -1123.716759       107.366663      -201.745258       -94.288999   \n",
      "3      -990.493523       218.350244      -360.377514        43.654988   \n",
      "4     -1185.264650      -771.009579       227.522258       398.429202   \n",
      "\n",
      "   hist_bin1  hist_bin2  hist_bin3  hist_bin4  hist_bin5  \n",
      "0   0.502551   0.039541   0.030612   0.130102   0.297194  \n",
      "1   0.448980   0.044643   0.038265   0.130102   0.338010  \n",
      "2   0.626276   0.323980   0.024235   0.011480   0.014031  \n",
      "3   0.524235   0.108418   0.302296   0.056122   0.008929  \n",
      "4   0.630102   0.019133   0.015306   0.035714   0.299745  \n",
      "\n",
      "Metadata Features (first 5 rows):\n",
      "  image_id  class_id   class_name data_split\n",
      "0    img_0         9   Ankle boot      train\n",
      "1    img_1         0  T-shirt/top      train\n",
      "2    img_2         0  T-shirt/top      train\n",
      "3    img_3         3        Dress      train\n",
      "4    img_4         0  T-shirt/top      train\n"
     ]
    }
   ],
   "source": [
    "# 9. Display sample rows\n",
    "print(\"\\nImage Features (first 5 rows):\")\n",
    "print(image_features_df.head())\n",
    "\n",
    "print(\"\\nMetadata Features (first 5 rows):\")\n",
    "print(metadata_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b52c9230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Features Statistics:\n",
      "       mean_brightness  std_deviation  edge_density  pca_component_1  \\\n",
      "count     70000.000000   70000.000000  70000.000000     70000.000000   \n",
      "mean         72.969811      81.649481    176.495030        17.998457   \n",
      "std          32.134516      20.019305     43.877835      1134.817214   \n",
      "min           4.943878      16.525658     32.577617     -2026.518314   \n",
      "25%          47.405293      66.923739    147.085311      -945.189249   \n",
      "50%          69.336735      84.541055    173.466071         0.600875   \n",
      "75%          97.354911      98.158086    203.357451       914.400001   \n",
      "max         191.820153     121.286206    475.178819      2798.851306   \n",
      "\n",
      "       pca_component_2  pca_component_3  pca_component_4  pca_component_5  \\\n",
      "count     70000.000000     70000.000000     70000.000000     70000.000000   \n",
      "mean         -6.440443         4.424498        -5.566805         4.030693   \n",
      "std         886.547650       516.046603       468.677947       412.592766   \n",
      "min       -1705.482076     -1639.980660     -1895.102146     -1873.296310   \n",
      "25%        -731.164484      -347.125797      -309.535793      -258.107815   \n",
      "50%          45.551437        54.573711        -5.405881        -4.975282   \n",
      "75%         667.987413       402.822913       305.999190       219.242830   \n",
      "max        2446.374296      1800.938822      1586.993879      1911.344724   \n",
      "\n",
      "          hist_bin1     hist_bin2     hist_bin3     hist_bin4     hist_bin5  \n",
      "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000  \n",
      "mean       0.576408      0.068834      0.083442      0.125702      0.145614  \n",
      "std        0.154614      0.085638      0.087032      0.112130      0.151467  \n",
      "min        0.082908      0.000000      0.000000      0.000000      0.001276  \n",
      "25%        0.448980      0.024235      0.029337      0.042092      0.024235  \n",
      "50%        0.572704      0.035714      0.048469      0.086735      0.082908  \n",
      "75%        0.700255      0.067602      0.100765      0.173469      0.232143  \n",
      "max        0.991071      0.659439      0.633929      0.668367      0.780612  \n"
     ]
    }
   ],
   "source": [
    "# 10. Display dataset statistics\n",
    "print(\"\\nImage Features Statistics:\")\n",
    "print(image_features_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11f177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "class_name\n",
      "Ankle boot     7000\n",
      "T-shirt/top    7000\n",
      "Dress          7000\n",
      "Pullover       7000\n",
      "Sneaker        7000\n",
      "Sandal         7000\n",
      "Trouser        7000\n",
      "Shirt          7000\n",
      "Coat           7000\n",
      "Bag            7000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 11. Count classes in metadata\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(metadata_features_df['class_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e86b0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV File Sizes:\n",
      "image_features.csv: 17.20 MB\n",
      "metadata_features.csv: 1.69 MB\n"
     ]
    }
   ],
   "source": [
    "# 12. Verify file sizes\n",
    "import os\n",
    "print(f\"\\nCSV File Sizes:\")\n",
    "print(f\"image_features.csv: {os.path.getsize('./features/image_features.csv') / (1024*1024):.2f} MB\")\n",
    "print(f\"metadata_features.csv: {os.path.getsize('./features/metadata_features.csv') / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf04b5",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7892a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow-GPU)",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
