{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mwucQvi41Gjj"
   },
   "source": [
    "# **Fashion-MNIST with `CNN`(s)**\n",
    "\n",
    "> Here, we will solve a very common Computer Vision project `Fashion MNIST` using `CNN`(Convolutional Neural Network).\n",
    "\n",
    "'''\n",
    "\n",
    "* `Fashion MNIST` is a `Image Classification` dataset with `28x28` grayscale images of `10` Fashion categories.\n",
    "* Here, we will build a` Deep Learning model` using `Convolutional Neural Networks (CNNs)` to solve this Image Classification problem.\n",
    "\n",
    "![Image](https://thiagolcmelo.github.io/assets/img/fashion-mnist.png)\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "W79bcuCL9cTZ"
   },
   "source": [
    "### **Importing Libraries**\n",
    "\n",
    "We will import some basic python libraires, such as:\n",
    "\n",
    "* `Numpy` - a Python library used for working with arrays.\n",
    "* `Pandas` - a Python library used for data analysis and manipulation.\n",
    "* `Matplotlib` - a plotting library for the Python programming language and its numerical mathematics extension NumPy.\n",
    "* Additionally, `%matplotlib inline` is a magic command in Jupyter Notebook that allows you to display plots in the notebook itself. It is used to set the backend of matplotlib to the inline backend.\n",
    "* `Pyplot` - a module in the Matplotlib library which provides a convenient interface for creating plots and charts.\n",
    "* `Tensorflow` - a free and open-source software library for machine learning and artificial intelligence.\n",
    "* `Keras` - an open-source high-level neural network library, which is written in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGXz99hx0_k1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9w7m2GJL-PwU"
   },
   "source": [
    "### **Importing Dataset**\n",
    "\n",
    "* Here we import Fashion MNIST dataset from `keras.datasets`.\n",
    "* There are `60,000` Train images and labels and `10,000` for Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-zKqn5nJ9v6f"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kcwzgzyVOuXt"
   },
   "source": [
    "* Also we will make a `list` of the `10 classes` (clothing categories). We will later use it to `predict` using our Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7rK1rbhZA97Q"
   },
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JVV7jxq6BqEt"
   },
   "source": [
    "### **Reshaping Data**\n",
    "\n",
    "* We will reshape our Train and Test Image dataset.\n",
    "* `60,000` and `10,000` are the number of images for `Train` and `Test` respectively.\n",
    "* `28,28` are the dimensions of the images in `pixels`.\n",
    "* And since the images are in `grayscale`, they only need `1` colour channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d0k1GUkjBZNf"
   },
   "outputs": [],
   "source": [
    "X_train_full = X_train_full.reshape((60000, 28,28, 1))\n",
    "X_test = X_test.reshape((10000, 28,28, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oAeWC78HD506"
   },
   "source": [
    "### **Split the data into Train/ Validation/ Test Datasets**\n",
    "\n",
    "* In the earlier step of importing the date, we had 60,000 datasets or Training and 10,000 Test datasets.\n",
    "* Now we further split the Training data into Train/ Validation. Here is how each type of dataset is used in Deep Learning.\n",
    "\n",
    "Use of each each type of Dataset in Deep Learning:-\n",
    "\n",
    "* `Training Data` - used for Training model.\n",
    "* `Validation Data` - used for tuning the Hyper-parameters and evaluate the Models.\n",
    "* `Test Data` - used to test the Model after the Model has been trained.\n",
    "\n",
    "'''\n",
    "\n",
    "* We will take first `5000` images and labels  out of the `60,000` as `Validation` dataset, and the rest for the model to `Train` on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OhXRnMVCDp30"
   },
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Class Distribution Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "class_counts = np.bincount(y_train_full)\n",
    "plt.bar(range(len(class_names)), class_counts)\n",
    "plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.xlabel('Clothing Type')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print class distribution\n",
    "print(\"Class Distribution:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"{name}: {class_counts[i]} samples ({class_counts[i]/len(y_train_full)*100:.1f}%)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "clCQ_XMvx6aJ"
   },
   "source": [
    "### **Data Augmentation**\n",
    "\n",
    "> `Data Augmentation` is a technique used in machine learning to `reduce overfitting` when training a machine learning model by training models on several `slightly-modified` copies of `existing data`.\n",
    "\n",
    "'''\n",
    "\n",
    "We will perform `Data Augmentation` on `Train` and `Validation` images using following Augmentation:-\n",
    "\n",
    "* `rescale=1./255` - used to convert the pixels in range `[0,255]` to range `[0,1]`. This process is also called `Normalizing the Input`.\n",
    "* `rotation_range=20` - used to `rotate` the image by `0 to 20 degrees`. This method of augmentation rotates the pixels of the image.\n",
    "* `width_shift_range=0.2` - used to `shift` the image in the `horizontal` direction.\n",
    "* `height_shift_range=0.2` - used to `shift` the image in the `vertical` direction.\n",
    "* `shear_range=0.2` - used to apply `shear` transformation to the image. `Shear` is a transformation that `shifts the rows or columns` of an image or a video frame by gradually `increasing the offset` from left to right or right to left.\n",
    "* `zoom_range=0.2` - used to apply `zoom` transformation to the image.\n",
    "* `horizontal_flip=True` - used to `flip` the image `horizontally`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5hDw2zvWx5gA"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Generating batches of tensor image data\n",
    "# Generating batches of tensor image data with more balanced augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,  # Less rotation to avoid distortion\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'  # Better handling of empty pixels after transformations\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "validation_generator = validation_datagen.flow(X_valid, y_valid, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "egJFAOubIvyq"
   },
   "source": [
    "### **Model Architecture**\n",
    "\n",
    "* Here we will build a `Convolutional Neural Network` using keras `Sequential API`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PK0iI2XJRUQ"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), strides=1, padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))  # Higher dropout before final classification\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LRVbi6ykQ2_U"
   },
   "source": [
    "#### **Architecture Explained**\n",
    "\n",
    "**1.** `Conv2D [2D Convolutional Neural Network]` - There are `3 Conv2D` networks. These networks are designed to progressively learn more complex features from the input images:\n",
    "\n",
    "* `filters` - We use an increasing number of filters (32→64→128) to capture progressively more complex patterns. The initial layer with 32 filters detects basic patterns like edges, textures, and simple shapes. The middle layer with 64 filters combines these basic features to form more complex patterns like clothing outlines. The final layer with 128 filters identifies high-level features specific to different clothing items.\n",
    "\n",
    "* `kernel_size` - The kernel_size of (3,3) provides a balance between capturing local patterns and computational efficiency. These 3×3 filters scan the entire image to detect relevant features.\n",
    "\n",
    "* `strides` - Using a stride of 1 ensures we don't miss any spatial information, as the filter moves one pixel at a time during convolution.\n",
    "\n",
    "* `padding` - Setting padding to \"same\" preserves the spatial dimensions of our feature maps, ensuring we don't lose information at the image borders.\n",
    "\n",
    "* `activation` - The ReLU (Rectified Linear Unit) activation function introduces non-linearity, allowing the network to learn complex patterns. ReLU is defined as f(x) = max(0,x), which outputs 0 for negative inputs and passes through positive values unchanged.\n",
    "\n",
    "* `input_shape` - The first layer takes input with shape (28,28,1), representing the width, height, and channel dimensions of our grayscale Fashion MNIST images.\n",
    "\n",
    "**2.** `MaxPooling2D` - After each convolutional layer, MaxPooling2D reduces the spatial dimensions of our feature maps:\n",
    "\n",
    "* Each MaxPooling2D layer with pool size (2,2) reduces the width and height by half, keeping only the maximum value from each 2×2 region.\n",
    "* This downsampling serves multiple purposes:\n",
    "  * Reducing computational complexity by decreasing the number of parameters\n",
    "  * Creating a form of translational invariance, helping the model recognize objects regardless of their exact position\n",
    "  * Focusing on the most important features while discarding less relevant details\n",
    "  * Each successive pooling layer increases the receptive field, allowing deeper layers to \"see\" larger portions of the original image\n",
    "\n",
    "**3.** `Dropout` - Added strategically after each pooling layer and the dense layer:\n",
    "\n",
    "* Dropout is a powerful regularization technique that randomly deactivates a percentage of neurons during each training iteration.\n",
    "* We use a 25% dropout rate (0.25) after each convolutional block to prevent overfitting.\n",
    "* A higher dropout rate of 50% (0.5) is applied after the dense layer, where the majority of model parameters reside.\n",
    "* Benefits of dropout include:\n",
    "  * Preventing co-adaptation of neurons (neurons becoming too dependent on each other)\n",
    "  * Creating an effect similar to ensemble learning, as each training batch effectively trains a slightly different network\n",
    "  * Forcing the network to learn more robust features that don't rely on specific neuron combinations\n",
    "\n",
    "**4.** `Flatten` - The Flatten layer transforms our 3D feature maps (width × height × channels) into a 1D vector:\n",
    "\n",
    "* After the final convolutional block, we have feature maps of reduced spatial dimensions but increased depth (more channels).\n",
    "* The Flatten layer takes these feature maps and stretches them into a single long vector.\n",
    "* This transformation is necessary to connect the convolutional layers to the fully connected (Dense) layers.\n",
    "* The flattening preserves all the extracted features while changing only their arrangement.\n",
    "\n",
    "**5.** `Dense` - We use two fully connected layers for final classification:\n",
    "\n",
    "* The first Dense layer has 512 neurons with ReLU activation:\n",
    "  * This layer interprets the high-level features extracted by the convolutional layers\n",
    "  * Its large number of neurons gives it the capacity to learn complex combinations of features\n",
    "  * The ReLU activation allows for non-linear separations in the feature space\n",
    "\n",
    "* The final Dense layer has 10 neurons (one for each clothing category) with softmax activation:\n",
    "  * Softmax transforms the raw outputs into a probability distribution over the 10 classes\n",
    "  * This ensures all outputs sum to 1 and fall between 0 and 1\n",
    "  * The neuron with the highest activation represents the model's classification\n",
    "\n",
    "This architecture balances model complexity with regularization, creating a network deep enough to learn the distinguishing features of clothing items while including dropout to prevent overfitting and ensure good generalization to unseen examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQnbmO6pK0HY",
    "outputId": "ddfa3904-251f-4a3a-f9e0-f5927ff4d72f"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Summary Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total parameters\n",
    "trainable_params = sum([np.prod(layer.get_weights()[0].shape) + np.prod(layer.get_weights()[1].shape if len(layer.get_weights()) > 1 else []) for layer in model.layers if layer.trainable_weights])\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Print per-layer parameter count for better understanding\n",
    "print(\"\\nParameter distribution by layer:\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.trainable_weights:\n",
    "        params = sum([np.prod(w.shape) for w in layer.get_weights()])\n",
    "        print(f\"Layer {i} ({layer.__class__.__name__}): {params:,} parameters ({params/trainable_params*100:.2f}%)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qQFWfPVF5-3m"
   },
   "source": [
    "### **Callbacks**\n",
    "\n",
    "* We will also use some `Callbacks` to improve our effectiveness and efficiency in training the Model.\n",
    "\n",
    "> `Callbacks` are functions that can be passed to a neural network `during training` to perform certain `actions at specific points` during the `training` process.\n",
    "\n",
    "* We will use following Callbacks -\n",
    "\n",
    "1. `early_stopping` - The `EarlyStopping` callback is a Keras callback that can be used to `stop the training process early` if the monitored value stops improving. Here we monitor `val_loss` and use `10` as `patience` value, which means the callback will wait `10 epochs` before executing.\n",
    "2. `model_checkpoint` - The `ModelCheckpoint` callback is a Keras callback that can be used to `save the weights` of the neural network at certain intervals during training. Here we will `save only best model`.\n",
    "3. `reduce_lr_on_plateau` - ReduceLROnPlateau is a callback that `monitors a quantity` and if no improvement is seen for a patience number of epochs, the `learning rate is reduced`. Here we reduce the learning rate by `10 percent`.\n",
    "4. `tensorboard` - TensorBoard is a `visualization tool` provided with TensorFlow. This callback `logs events` for TensorBoard, including metrics summary plots, training graph visualization, weight histograms, and sampled profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hG-UPCH86DhG"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor accuracy instead of loss\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    mode='max'  # Looking for maximum accuracy\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,  # More gradual reduction\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_delta=0.001,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint, reduce_lr_on_plateau, tensorboard]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wwxphlf56Guh"
   },
   "source": [
    "### **Training Model**\n",
    "\n",
    "* Building of every `batch` used into training uses random images.\n",
    "* Before beginning to train, we will set `random seed number`, so that every time we train our model we get the `same results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6NwedQz16Izw"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "N41CZth-1TrC"
   },
   "source": [
    "We then compile our model using -\n",
    "\n",
    "* `sparse_categorical_crossentropy` - We use this as our `loss` function as we are training a `Multi-Class Classification` model.\n",
    "* `sgd` - `Stochastic Gradient Descent` (SGD) is an iterative method for `minimizing a function`, such as the loss or error function, by moving in the direction of the gradient. It is a type of `gradient descent` optimizer that uses a `randomly selected subset` of the data instead of the entire data set for each iteration.\n",
    "* `accuracy` -  The metrics argument is used to specify the metrics to be `evaluated` by the model during `training and testing`. Here we use `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xAlhqLu3K5kX"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "J88AA3Wt1piX"
   },
   "source": [
    "* Now we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOr1W_ACLLQi",
    "outputId": "467d161e-470f-4046-d9b6-f5add26c696f"
   },
   "outputs": [],
   "source": [
    "# Calculate steps based on actual dataset size\n",
    "steps_per_epoch = len(X_train) // 32  # Based on batch size\n",
    "validation_steps = len(X_valid) // 32\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=100,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qYgOgacqirvr"
   },
   "source": [
    "### **Plotting Performance Graphs**\n",
    "\n",
    "* Here we plot a performance graph showing our `Train` and `Validation` `loss` and `accurracy` along with the `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "CHtxlBwTI94Z",
    "outputId": "33610e27-c2e5-4e96-a690-53bfdc579b16"
   },
   "outputs": [],
   "source": [
    "# Plot accuracy and loss with clear markers for learning rate changes\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o', markersize=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o', markersize=2)\n",
    "\n",
    "# Find points where learning rate changed\n",
    "lr_changes = []\n",
    "for i in range(1, len(history.history['lr'])):\n",
    "    if history.history['lr'][i] < history.history['lr'][i-1]:\n",
    "        lr_changes.append(i)\n",
    "\n",
    "# Mark learning rate changes\n",
    "for change in lr_changes:\n",
    "    plt.axvline(x=change, color='r', linestyle='--', alpha=0.3)\n",
    "    plt.text(change, 0.5, f\"LR ÷ 5\", rotation=90, verticalalignment='center')\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='o', markersize=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o', markersize=2)\n",
    "\n",
    "# Mark learning rate changes on loss plot too\n",
    "for change in lr_changes:\n",
    "    plt.axvline(x=change, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add Confusion Matrix Analysis**\n",
    "\n",
    "##### **Model Error Analysis**\n",
    "\n",
    "The confusion matrix above shows the distribution of correct and incorrect classifications:\n",
    "- Each row represents a true class\n",
    "- Each column represents a predicted class\n",
    "- The diagonal elements show correct classifications\n",
    "- Off-diagonal elements show misclassifications\n",
    "\n",
    "The most common errors typically occur between similar clothing items, such as:\n",
    "- Shirts, T-shirts, and Pullovers\n",
    "- Ankle boots and Sneakers\n",
    "- Dresses and Coats\n",
    "\n",
    "The classification report provides precision, recall, and F1-score for each class, helping identify which categories are most challenging for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Get predictions\n",
    "X_test_shaped = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "y_pred_probs = model.predict(X_test_shaped)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Create and plot confusion matrix\n",
    "plt.figure(figsize=(14, 10))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Classes')\n",
    "plt.ylabel('True Classes')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Visualization**\n",
    "\n",
    "##### **Prediction Visualization with Confidence**\n",
    "\n",
    "Below is a visualization of model predictions on random test images:\n",
    "- Green titles indicate correct classifications\n",
    "- Red titles indicate misclassifications\n",
    "- Confidence percentages show the model's certainty about each prediction\n",
    "- This helps identify patterns in model errors and confidence levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model predictions with confidence scores\n",
    "def plot_predictions_with_confidence(images, true_labels, predictions, class_names, n=25):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(min(n, len(images))):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        \n",
    "        predicted_class = np.argmax(predictions[i])\n",
    "        confidence = predictions[i][predicted_class] * 100\n",
    "        \n",
    "        # Green for correct, red for incorrect\n",
    "        color = 'green' if predicted_class == true_labels[i] else 'red'\n",
    "        \n",
    "        title = f\"{class_names[true_labels[i]]}\\nvs\\n{class_names[predicted_class]}\\n{confidence:.1f}%\"\n",
    "        plt.title(title, color=color, fontsize=9)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get random sample from test set\n",
    "indices = np.random.choice(len(X_test), 25, replace=False)\n",
    "sample_images = X_test[indices]\n",
    "sample_labels = y_test[indices]\n",
    "sample_images_shaped = sample_images.reshape(-1, 28, 28, 1)\n",
    "sample_predictions = model.predict(sample_images_shaped)\n",
    "\n",
    "# Visualize predictions with confidence\n",
    "plot_predictions_with_confidence(sample_images, sample_labels, sample_predictions, class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2ERMzE01bQLr"
   },
   "source": [
    "### **Loading Best Model**\n",
    "\n",
    "* We first use `clear_session` to free up our memory and then delete the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbGY-D2UbRmh",
    "outputId": "c0dacbad-8d30-4524-e84d-6eccb70f3029"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ee0INurrbTuc"
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3T0iN-Kf2Qp1"
   },
   "source": [
    "* Now we load the `Best model` that our `callback` saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5BxYz7y1mCA"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wSJb9uTP1fLI"
   },
   "source": [
    "### **Evaluating Model**\n",
    "\n",
    "* Here we evaluate the overall `performance` of our model on the `Test Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WrvsrL6ijHxJ",
    "outputId": "6970723e-feb7-46ef-fc7f-e41e9fbd8c83"
   },
   "outputs": [],
   "source": [
    "result = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BW1xozH_jdNP",
    "outputId": "0c1d4f3e-d1cc-4945-fc6e-73eb1de447c5"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2A1a6Eo4awvW"
   },
   "source": [
    "### **Predicting Classes**\n",
    "\n",
    "* Now we will `predict classes` using our model.\n",
    "* First we take a small subset from our `Test Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5Xr7dJejgmm"
   },
   "outputs": [],
   "source": [
    "X_new = X_test[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wcX2tFSA3LhX"
   },
   "source": [
    "* The we use predict function using our model on the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9V3rU006jrBu",
    "outputId": "6009d0d8-8e07-4143-8468-7012753120ed"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_new) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PSAxDN853sbF"
   },
   "source": [
    "* Rounding off to 2 Decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkiOK_QE3mul"
   },
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zBBfKLlU3w2M"
   },
   "source": [
    "* Making an array of the position of the highest number present in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-CRYJn33o6l",
    "outputId": "ef670b32-90f7-4fe5-8462-cbe46f5e7349"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "K0C4BN9S35R0"
   },
   "source": [
    "* Now we see the values in our Test Subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2rAXxRUj7PF",
    "outputId": "dff774d6-9280-458c-fed6-1d82df1aa04f"
   },
   "outputs": [],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vlC698Fo4AwL"
   },
   "source": [
    "* Our model predicted it accurately.\n",
    "\n",
    "'''\n",
    "\n",
    "* Let's Display the first image in our Subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "S3J08XJjnyyB",
    "outputId": "b88ba500-9b8c-4f6b-ea86-be15ff670a35"
   },
   "outputs": [],
   "source": [
    "print(plt.imshow(X_test[0].reshape((28,28))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz2Ja21J4YOx"
   },
   "source": [
    "* And the value model predicted for the first image was `9` which according to our `class_names` list is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8SfbF2YMOVDo",
    "outputId": "1a18f3c0-5f02-4483-e1c3-ac7ff82c8cb3"
   },
   "outputs": [],
   "source": [
    "class_names[9]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eXZ65WY64p2Q"
   },
   "source": [
    "* Seems to match perfectly.\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhvAJvYBoQXP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
