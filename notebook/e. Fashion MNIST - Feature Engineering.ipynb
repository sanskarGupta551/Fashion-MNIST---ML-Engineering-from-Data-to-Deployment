{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e3219d",
   "metadata": {},
   "source": [
    "# **Fashion MNIST: Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7a6af",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "### **Introduction to Feature Engineering**\n",
    "\n",
    "This notebook demonstrates experimental feature engineering for the Fashion MNIST dataset. While deep neural networks can automatically learn hierarchical features from raw pixel data, explicit feature engineering provides several advantages for analysis:\n",
    "\n",
    "1. Creates `interpretable features` that help us understand what distinguishes different clothing categories\n",
    "2. Enables traditional ML algorithms to work with image data through meaningful transformations\n",
    "3. Facilitates `feature store integration` for consistent access across training and serving\n",
    "4. Provides insights into underlying data characteristics without full model training\n",
    "5. Creates features that can be used for `exploratory data analysis` and visualization\n",
    "\n",
    "The extracted features will be organized into two logical groups:\n",
    "- `Image features`: Statistical, structural, and dimensionality-based features derived from raw pixels\n",
    "- `Metadata features`: Class labels, identifiers, and dataset split information\n",
    "\n",
    "This approach is primarily for experimental analysis rather than direct implementation in our training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928f3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:24:12.699821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745850252.712526   34706 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745850252.716240   34706 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745850252.727362   34706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745850252.727381   34706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745850252.727382   34706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745850252.727383   34706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 14:24:12.731301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23bc1d",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Data Preparation**\n",
    "\n",
    "Our feature engineering process begins with loading the Fashion MNIST dataset using TensorFlow's datasets API. The dataset consists of:\n",
    "\n",
    "- `60,000 training images` (28×28 grayscale pixels)\n",
    "- `10,000 test images` (28×28 grayscale pixels)\n",
    "- 10 clothing categories with balanced class distribution\n",
    "\n",
    "We'll assign each image a class name from the predefined list to make the features more interpretable and facilitate analysis by category. These class names will be included in our metadata features table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf005d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 2. Define class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe032de6",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "### **Dataset Combination**\n",
    "\n",
    "For feature extraction, we'll first combine the training and test datasets while maintaining split information. This approach allows us to:\n",
    "\n",
    "1. Process all `70,000 images` with a single feature extraction pipeline\n",
    "2. Keep track of the original data `split designation` (train/test) as metadata\n",
    "3. Generate consistent features across both splits\n",
    "4. Create a unified feature set that can later be separated as needed\n",
    "\n",
    "This combined approach simplifies the feature extraction workflow while preserving important provenance information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.concatenate([x_train, x_test])\n",
    "y_all = np.concatenate([y_train, y_test])\n",
    "split_labels = ['train'] * len(x_train) + ['test'] * len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47576944",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Dimensionality Reduction with PCA**\n",
    "\n",
    "Principal Component Analysis (PCA) is a powerful technique for extracting the most important dimensions from high-dimensional data. For our 28×28 pixel images (784 dimensions), we:\n",
    "\n",
    "1. Flatten each image into a `784-dimensional vector`\n",
    "2. Fit PCA on a random subset of `10,000 images` to save memory and computation time\n",
    "3. Retain the `top 10 principal components` that capture the most variance\n",
    "4. Transform all 70,000 images to this lower-dimensional representation\n",
    "\n",
    "PCA components represent directions of maximum variance in the data and often correspond to meaningful visual patterns. These components will be included in our feature set to provide a compact representation of image content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images for PCA\n",
    "x_flat = x_all.reshape(x_all.shape[0], -1)\n",
    "\n",
    "# Fit PCA on a subset to save memory\n",
    "sample_size = 10000\n",
    "random_indices = np.random.choice(len(x_flat), sample_size, replace=False)\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(x_flat[random_indices])\n",
    "\n",
    "# Transform all data\n",
    "pca_results = pca.transform(x_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96308261",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "### **Feature Extraction Strategy**\n",
    "\n",
    "Our feature extraction function calculates several types of engineered features for each image:\n",
    "\n",
    "1. **Statistical Features**:\n",
    "   - `Mean brightness`: Average pixel value across the image\n",
    "   - `Standard deviation`: Variation in pixel intensity\n",
    "\n",
    "2. **Edge Features**:\n",
    "   - Sobel operators to detect edges in x and y directions\n",
    "   - `Edge density`: Mean magnitude of edge gradients across the image\n",
    "\n",
    "3. **Histogram Features**:\n",
    "   - Distribution of pixel intensities divided into `5 bins`\n",
    "   - Normalized to sum to 1.0 for scale invariance\n",
    "\n",
    "These handcrafted features capture different aspects of the images that may be useful for classification tasks, particularly when using traditional machine learning models or for interpretability purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226da4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    # Basic statistics\n",
    "    mean_brightness = np.mean(image)\n",
    "    std_deviation = np.std(image)\n",
    "    \n",
    "    # Edge detection\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    edge_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    edge_density = np.mean(edge_magnitude)\n",
    "    \n",
    "    # Histogram features (5 bins)\n",
    "    hist, _ = np.histogram(image, bins=5, range=(0, 255))\n",
    "    hist = hist / np.sum(hist)  # Normalize\n",
    "    \n",
    "    return {\n",
    "        'mean_brightness': mean_brightness,\n",
    "        'std_deviation': std_deviation,\n",
    "        'edge_density': edge_density,\n",
    "        'hist_bin1': hist[0],\n",
    "        'hist_bin2': hist[1],\n",
    "        'hist_bin3': hist[2],\n",
    "        'hist_bin4': hist[3],\n",
    "        'hist_bin5': hist[4]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c0513",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Feature Processing Pipeline**\n",
    "\n",
    "The feature extraction pipeline processes all 70,000 images to generate two distinct feature sets:\n",
    "\n",
    "1. **Image Features**:\n",
    "   - Unique `image_id` as primary key\n",
    "   - Statistical features (mean brightness, standard deviation)\n",
    "   - Structural features (edge density)\n",
    "   - Dimensionality reduction features (top 5 PCA components)\n",
    "   - Histogram features (5 bins representing pixel value distribution)\n",
    "\n",
    "2. **Metadata Features**:\n",
    "   - Unique `image_id` as primary key (for joining)\n",
    "   - Class information (numeric ID and readable name)\n",
    "   - Dataset split designation (train/test)\n",
    "\n",
    "This separation follows data modeling best practices by organizing features into logical groups with appropriate relationships. The `image_id` serves as the joining key between these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80694e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/70000 images\n",
      "Processed 10000/70000 images\n",
      "Processed 20000/70000 images\n",
      "Processed 30000/70000 images\n",
      "Processed 40000/70000 images\n",
      "Processed 50000/70000 images\n",
      "Processed 60000/70000 images\n"
     ]
    }
   ],
   "source": [
    "image_features = []\n",
    "metadata_features = []\n",
    "\n",
    "for i in range(len(x_all)):\n",
    "    # Generate unique image ID\n",
    "    image_id = f\"img_{i}\"\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(x_all[i])\n",
    "    \n",
    "    # Image features\n",
    "    image_features.append({\n",
    "        'image_id': image_id,\n",
    "        'mean_brightness': features['mean_brightness'],\n",
    "        'std_deviation': features['std_deviation'],\n",
    "        'edge_density': features['edge_density'],\n",
    "        'pca_component_1': pca_results[i][0],\n",
    "        'pca_component_2': pca_results[i][1],\n",
    "        'pca_component_3': pca_results[i][2],\n",
    "        'pca_component_4': pca_results[i][3],\n",
    "        'pca_component_5': pca_results[i][4],\n",
    "        'hist_bin1': features['hist_bin1'],\n",
    "        'hist_bin2': features['hist_bin2'],\n",
    "        'hist_bin3': features['hist_bin3'],\n",
    "        'hist_bin4': features['hist_bin4'],\n",
    "        'hist_bin5': features['hist_bin5']\n",
    "    })\n",
    "\n",
    "    \n",
    "    # Metadata features\n",
    "    metadata_features.append({\n",
    "        'image_id': image_id,\n",
    "        'class_id': int(y_all[i]),\n",
    "        'class_name': class_names[y_all[i]],\n",
    "        'data_split': split_labels[i]\n",
    "    })\n",
    "    \n",
    "    # Show progress\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Processed {i}/{len(x_all)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb543ef",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Data Persistence**\n",
    "\n",
    "After generating our feature sets, we persist them to CSV files for further analysis and potential integration with other systems. The CSV format offers several advantages:\n",
    "\n",
    "1. `Universal compatibility` with various data analysis tools\n",
    "2. Easy import into databases or feature stores\n",
    "3. Human-readable format for inspection and debugging\n",
    "4. Efficient storage for tabular data\n",
    "\n",
    "These CSV files will be stored in the `./features/` directory and could be uploaded to Google Cloud Storage or imported into BigQuery for further analysis and feature serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce805a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_df = pd.DataFrame(image_features)\n",
    "metadata_features_df = pd.DataFrame(metadata_features)\n",
    "\n",
    "# 8. Save to CSV\n",
    "image_features_df.to_csv('./features/image_features.csv', index=False)\n",
    "metadata_features_df.to_csv('./features/metadata_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d875f48",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Feature Exploration**\n",
    "\n",
    "The sample rows display shows our extracted features for the first 5 images, allowing us to inspect the data structure and verify the feature generation process. Key observations:\n",
    "\n",
    "1. Each image has a unique `image_id` that serves as the primary key\n",
    "2. Image features include statistical, structural, and PCA-based components\n",
    "3. Metadata includes both numeric `class_id` and human-readable `class_name`\n",
    "4. The `data_split` column preserves the original dataset designation\n",
    "\n",
    "This tabular format transforms unstructured image data into structured features that can be used for visualization, analysis, and traditional machine learning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e331b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Features (first 5 rows):\n",
      "  image_id  mean_brightness  std_deviation  edge_density  pca_component_1  \\\n",
      "0    img_0        97.253827     101.792346    192.181315      -133.960372   \n",
      "1    img_1       107.905612     100.831448    225.351588      1420.510590   \n",
      "2    img_2        36.558673      49.698752     83.301051      -692.044930   \n",
      "3    img_3        59.501276      64.849295    136.712344        60.543575   \n",
      "4    img_4        78.044643     103.843248    190.411598       838.742679   \n",
      "\n",
      "   pca_component_2  pca_component_3  pca_component_4  pca_component_5  \\\n",
      "0      1634.674432     -1180.050450      -351.047373         9.991461   \n",
      "1      -425.358405      -224.046959      -361.054253       290.012937   \n",
      "2     -1123.716759       107.366663      -201.745258       -94.288999   \n",
      "3      -990.493523       218.350244      -360.377514        43.654988   \n",
      "4     -1185.264650      -771.009579       227.522258       398.429202   \n",
      "\n",
      "   hist_bin1  hist_bin2  hist_bin3  hist_bin4  hist_bin5  \n",
      "0   0.502551   0.039541   0.030612   0.130102   0.297194  \n",
      "1   0.448980   0.044643   0.038265   0.130102   0.338010  \n",
      "2   0.626276   0.323980   0.024235   0.011480   0.014031  \n",
      "3   0.524235   0.108418   0.302296   0.056122   0.008929  \n",
      "4   0.630102   0.019133   0.015306   0.035714   0.299745  \n",
      "\n",
      "Metadata Features (first 5 rows):\n",
      "  image_id  class_id   class_name data_split\n",
      "0    img_0         9   Ankle boot      train\n",
      "1    img_1         0  T-shirt/top      train\n",
      "2    img_2         0  T-shirt/top      train\n",
      "3    img_3         3        Dress      train\n",
      "4    img_4         0  T-shirt/top      train\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nImage Features (first 5 rows):\")\n",
    "print(image_features_df.head())\n",
    "\n",
    "print(\"\\nMetadata Features (first 5 rows):\")\n",
    "print(metadata_features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e500d4",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "### **Statistical Analysis**\n",
    "\n",
    "The statistical summary provides insights into the distribution of our engineered features across the entire dataset:\n",
    "\n",
    "1. **Mean Brightness**: Ranges from ~5 to ~192 with mean around `73`\n",
    "2. **Standard Deviation**: Ranges from ~17 to ~121 with mean around `82`\n",
    "3. **Edge Density**: Ranges from ~33 to ~475 with mean around `176`\n",
    "4. **PCA Components**: Show typical zero-centered distributions\n",
    "5. **Histogram Bins**: The first bin (darkest pixels) has the highest average proportion (~58%)\n",
    "\n",
    "These statistics help us understand the range and distribution of our features, which is essential for feature normalization, outlier detection, and interpretation of model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c9230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Features Statistics:\n",
      "       mean_brightness  std_deviation  edge_density  pca_component_1  \\\n",
      "count     70000.000000   70000.000000  70000.000000     70000.000000   \n",
      "mean         72.969811      81.649481    176.495030        17.998457   \n",
      "std          32.134516      20.019305     43.877835      1134.817214   \n",
      "min           4.943878      16.525658     32.577617     -2026.518314   \n",
      "25%          47.405293      66.923739    147.085311      -945.189249   \n",
      "50%          69.336735      84.541055    173.466071         0.600875   \n",
      "75%          97.354911      98.158086    203.357451       914.400001   \n",
      "max         191.820153     121.286206    475.178819      2798.851306   \n",
      "\n",
      "       pca_component_2  pca_component_3  pca_component_4  pca_component_5  \\\n",
      "count     70000.000000     70000.000000     70000.000000     70000.000000   \n",
      "mean         -6.440443         4.424498        -5.566805         4.030693   \n",
      "std         886.547650       516.046603       468.677947       412.592766   \n",
      "min       -1705.482076     -1639.980660     -1895.102146     -1873.296310   \n",
      "25%        -731.164484      -347.125797      -309.535793      -258.107815   \n",
      "50%          45.551437        54.573711        -5.405881        -4.975282   \n",
      "75%         667.987413       402.822913       305.999190       219.242830   \n",
      "max        2446.374296      1800.938822      1586.993879      1911.344724   \n",
      "\n",
      "          hist_bin1     hist_bin2     hist_bin3     hist_bin4     hist_bin5  \n",
      "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000  \n",
      "mean       0.576408      0.068834      0.083442      0.125702      0.145614  \n",
      "std        0.154614      0.085638      0.087032      0.112130      0.151467  \n",
      "min        0.082908      0.000000      0.000000      0.000000      0.001276  \n",
      "25%        0.448980      0.024235      0.029337      0.042092      0.024235  \n",
      "50%        0.572704      0.035714      0.048469      0.086735      0.082908  \n",
      "75%        0.700255      0.067602      0.100765      0.173469      0.232143  \n",
      "max        0.991071      0.659439      0.633929      0.668367      0.780612  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nImage Features Statistics:\")\n",
    "print(image_features_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd865b",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Class Distribution Verification**\n",
    "\n",
    "The class distribution confirms that our feature set maintains the balanced nature of the original Fashion MNIST dataset:\n",
    "\n",
    "- Each of the 10 classes contains exactly `7,000 images` (combining train and test)\n",
    "- This balanced distribution is important for unbiased model training and evaluation\n",
    "- The alphabetical ordering differs from the original class_id ordering\n",
    "\n",
    "This verification step ensures that our feature engineering process preserved the integrity of the dataset structure while transforming the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "class_name\n",
      "Ankle boot     7000\n",
      "T-shirt/top    7000\n",
      "Dress          7000\n",
      "Pullover       7000\n",
      "Sneaker        7000\n",
      "Sandal         7000\n",
      "Trouser        7000\n",
      "Shirt          7000\n",
      "Coat           7000\n",
      "Bag            7000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClass Distribution:\")\n",
    "print(metadata_features_df['class_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d52791",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Storage Efficiency**\n",
    "\n",
    "The file size analysis shows:\n",
    "\n",
    "- `image_features.csv`: 17.20 MB\n",
    "- `metadata_features.csv`: 1.69 MB\n",
    "\n",
    "These CSV files provide an efficient representation of the dataset's essential characteristics:\n",
    "- The feature files are significantly smaller than the raw images (~17 MB vs ~70 MB)\n",
    "- The separation into two tables optimizes storage by preventing redundancy\n",
    "- The files are small enough for easy handling in memory on standard machines\n",
    "\n",
    "This compact representation facilitates rapid experimentation and analysis while maintaining the most informative aspects of the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86b0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV File Sizes:\n",
      "image_features.csv: 17.20 MB\n",
      "metadata_features.csv: 1.69 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"\\nCSV File Sizes:\")\n",
    "print(f\"image_features.csv: {os.path.getsize('./features/image_features.csv') / (1024*1024):.2f} MB\")\n",
    "print(f\"metadata_features.csv: {os.path.getsize('./features/metadata_features.csv') / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2172c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "This experimental feature engineering notebook has successfully:\n",
    "\n",
    "1. Transformed 70,000 Fashion MNIST images into structured, tabular feature sets\n",
    "2. Created `13 engineered features` capturing statistical, structural, and distributional characteristics\n",
    "3. Preserved essential metadata including class information and dataset splits\n",
    "4. Organized features into logical tables with proper relationships\n",
    "5. Generated analysis-ready CSV files for further exploration\n",
    "\n",
    "These features provide an alternative representation of the Fashion MNIST dataset that can be used for:\n",
    "\n",
    "- Exploratory data analysis and visualization\n",
    "- Training traditional ML models (random forests, gradient boosting, etc.)\n",
    "- Integration with `Vertex AI Feature Store` for feature serving\n",
    "- Understanding which characteristics distinguish different clothing categories\n",
    "- Supplementing deep learning approaches with interpretable features\n",
    "\n",
    "While our production training pipeline will likely use the raw pixel data for deep learning models, these engineered features provide valuable insights and alternative modeling approaches for experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf04b5",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7892a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow-GPU)",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
