{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad94507",
   "metadata": {},
   "source": [
    "# **Fashion MNIST: Raw Data Analysis**\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c53cc08",
   "metadata": {},
   "source": [
    "### **Import Libraries and Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import cv2\n",
    "import json\n",
    "from datetime import datetime\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f173ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for analysis results\n",
    "os.makedirs('./analysis_results', exist_ok=True)\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Define class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc959a5",
   "metadata": {},
   "source": [
    "### **1. Dataset Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420601c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset Overview\n",
    "def analyze_dataset_overview():\n",
    "    # Class distribution\n",
    "    train_dist = np.bincount(y_train)\n",
    "    test_dist = np.bincount(y_test)\n",
    "    \n",
    "    # Create distribution visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    ax1.bar(class_names, train_dist)\n",
    "    ax1.set_title('Training Set Class Distribution')\n",
    "    ax1.set_xlabel('Class')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    ax2.bar(class_names, test_dist)\n",
    "    ax2.set_title('Test Set Class Distribution')\n",
    "    ax2.set_xlabel('Class')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/01_class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Save distribution data\n",
    "    distribution_data = {\n",
    "        'train_distribution': dict(zip(class_names, train_dist.tolist())),\n",
    "        'test_distribution': dict(zip(class_names, test_dist.tolist())),\n",
    "        'image_shape': X_train[0].shape,\n",
    "        'total_train_samples': len(X_train),\n",
    "        'total_test_samples': len(X_test)\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/01_dataset_overview.json', 'w') as f:\n",
    "        json.dump(distribution_data, f, indent=4)\n",
    "    \n",
    "    # Display summary in notebook\n",
    "    print(\"\\nDataset Overview:\")\n",
    "    print(f\"Total training samples: {distribution_data['total_train_samples']}\")\n",
    "    print(f\"Total test samples: {distribution_data['total_test_samples']}\")\n",
    "    print(f\"Image shape: {distribution_data['image_shape']}\")\n",
    "    \n",
    "    return distribution_data\n",
    "\n",
    "overview_data = analyze_dataset_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e42ffd5",
   "metadata": {},
   "source": [
    "### **2. Statistical Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb5d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Statistical Analysis\n",
    "def statistical_analysis():\n",
    "    # Global statistics\n",
    "    global_mean = np.mean(X_train)\n",
    "    global_std = np.std(X_train)\n",
    "    \n",
    "    # Class-specific statistics\n",
    "    class_stats = {}\n",
    "    for i in range(10):\n",
    "        class_data = X_train[y_train == i]\n",
    "        class_stats[class_names[i]] = {\n",
    "            'mean': float(np.mean(class_data)),\n",
    "            'std': float(np.std(class_data)),\n",
    "            'min': float(np.min(class_data)),\n",
    "            'max': float(np.max(class_data)),\n",
    "            'median': float(np.median(class_data))\n",
    "        }\n",
    "    \n",
    "    # Pixel intensity distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(X_train.flatten(), bins=50, alpha=0.7)\n",
    "    plt.title('Pixel Intensity Distribution')\n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig('./analysis_results/02_pixel_intensity_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Class-wise brightness analysis\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    brightness_data = []\n",
    "    for i in range(10):\n",
    "        class_data = X_train[y_train == i]\n",
    "        brightness_data.append(np.mean(class_data, axis=(1, 2)))\n",
    "    \n",
    "    ax.boxplot(brightness_data, labels=class_names)\n",
    "    ax.set_title('Class-wise Brightness Distribution')\n",
    "    ax.set_ylabel('Mean Brightness')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/02_class_brightness_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Save statistical data\n",
    "    stats_data = {\n",
    "        'global_statistics': {\n",
    "            'mean': float(global_mean),\n",
    "            'std': float(global_std)\n",
    "        },\n",
    "        'class_statistics': class_stats\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/02_statistical_analysis.json', 'w') as f:\n",
    "        json.dump(stats_data, f, indent=4)\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nGlobal Statistics:\")\n",
    "    print(f\"Mean pixel value: {global_mean:.2f}\")\n",
    "    print(f\"Standard deviation: {global_std:.2f}\")\n",
    "    \n",
    "    # Create a DataFrame for class statistics\n",
    "    stats_df = pd.DataFrame(class_stats).T\n",
    "    display(stats_df.round(2))\n",
    "    \n",
    "    return stats_data\n",
    "\n",
    "stats_data = statistical_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df36496",
   "metadata": {},
   "source": [
    "### **3. Visual Pattern Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f1645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visual Pattern Analysis\n",
    "def visual_pattern_analysis():\n",
    "    # Sample images for each class\n",
    "    fig, axes = plt.subplots(10, 10, figsize=(15, 15))\n",
    "    for i in range(10):\n",
    "        class_indices = np.where(y_train == i)[0][:10]\n",
    "        for j in range(10):\n",
    "            axes[i, j].imshow(X_train[class_indices[j]], cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "            if j == 0:\n",
    "                axes[i, j].set_ylabel(class_names[i], rotation=90, size='large')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/03_class_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Edge detection analysis\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i in range(10):\n",
    "        class_example = X_train[y_train == i][0]\n",
    "        edges = cv2.Canny(class_example, 100, 200)\n",
    "        \n",
    "        ax = axes[i // 5, i % 5]\n",
    "        ax.imshow(edges, cmap='gray')\n",
    "        ax.set_title(class_names[i])\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/03_edge_detection_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Average image per class\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    average_images = []\n",
    "    for i in range(10):\n",
    "        class_images = X_train[y_train == i]\n",
    "        avg_img = np.mean(class_images, axis=0)\n",
    "        average_images.append(avg_img)\n",
    "        \n",
    "        ax = axes[i // 5, i % 5]\n",
    "        ax.imshow(avg_img, cmap='gray')\n",
    "        ax.set_title(f'Average {class_names[i]}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/03_average_class_images.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    return average_images\n",
    "\n",
    "average_images = visual_pattern_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361f820",
   "metadata": {},
   "source": [
    "### **4. Dimensionality Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dimensionality Analysis\n",
    "def dimensionality_analysis():\n",
    "    # Reshape data for analysis\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    \n",
    "    # PCA Analysis\n",
    "    pca = PCA(n_components=50)\n",
    "    X_pca = pca.fit_transform(X_train_flat)\n",
    "    \n",
    "    # Plot explained variance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "    plt.title('PCA: Explained Variance vs Components')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('./analysis_results/04_pca_explained_variance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # t-SNE visualization (using a subset for efficiency)\n",
    "    np.random.seed(42)\n",
    "    subset_indices = np.random.choice(len(X_train_flat), 5000, replace=False)\n",
    "    X_subset = X_train_flat[subset_indices]\n",
    "    y_subset = y_train[subset_indices]\n",
    "    \n",
    "    print(\"Computing t-SNE (this may take a minute)...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    X_tsne = tsne.fit_transform(X_subset)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_subset, cmap='tab10', alpha=0.6)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title('t-SNE Visualization of Fashion MNIST')\n",
    "    \n",
    "    # Add class labels\n",
    "    for i in range(10):\n",
    "        plt.annotate(class_names[i], \n",
    "                    xy=(np.mean(X_tsne[y_subset == i, 0]), \n",
    "                        np.mean(X_tsne[y_subset == i, 1])),\n",
    "                    xytext=(5, 5), textcoords='offset points',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', fc='yellow', alpha=0.7))\n",
    "    \n",
    "    plt.savefig('./analysis_results/04_tsne_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Save dimensionality data\n",
    "    dim_data = {\n",
    "        'pca_explained_variance_ratio': pca.explained_variance_ratio_.tolist(),\n",
    "        'pca_components_needed_95': int(np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1)\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/04_dimensionality_analysis.json', 'w') as f:\n",
    "        json.dump(dim_data, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nComponents needed for 95% variance: {dim_data['pca_components_needed_95']}\")\n",
    "    \n",
    "    return dim_data\n",
    "\n",
    "dim_data = dimensionality_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922c563f",
   "metadata": {},
   "source": [
    "### **5. Class Relationship Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8576d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Class Relationship Analysis\n",
    "def class_relationship_analysis():\n",
    "    # Calculate class centroids\n",
    "    centroids = []\n",
    "    for i in range(10):\n",
    "        class_images = X_train[y_train == i]\n",
    "        centroid = np.mean(class_images, axis=0)\n",
    "        centroids.append(centroid.flatten())\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = cosine_similarity(centroids)\n",
    "    \n",
    "    # Plot similarity heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(similarity_matrix, annot=True, cmap='coolwarm', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Class Similarity Matrix (Cosine Similarity)')\n",
    "    plt.savefig('./analysis_results/05_class_similarity_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Identify most similar class pairs\n",
    "    similar_pairs = []\n",
    "    for i in range(10):\n",
    "        for j in range(i + 1, 10):\n",
    "            similar_pairs.append({\n",
    "                'class1': class_names[i],\n",
    "                'class2': class_names[j],\n",
    "                'similarity': float(similarity_matrix[i, j])\n",
    "            })\n",
    "    \n",
    "    similar_pairs.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    # Save relationship data\n",
    "    relationship_data = {\n",
    "        'similarity_matrix': similarity_matrix.tolist(),\n",
    "        'most_similar_pairs': similar_pairs[:5],\n",
    "        'least_similar_pairs': similar_pairs[-5:]\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/05_class_relationships.json', 'w') as f:\n",
    "        json.dump(relationship_data, f, indent=4)\n",
    "    \n",
    "    # Display most and least similar pairs\n",
    "    print(\"\\nMost similar class pairs:\")\n",
    "    for pair in relationship_data['most_similar_pairs']:\n",
    "        print(f\"{pair['class1']} - {pair['class2']}: {pair['similarity']:.3f}\")\n",
    "    \n",
    "    print(\"\\nLeast similar class pairs:\")\n",
    "    for pair in relationship_data['least_similar_pairs']:\n",
    "        print(f\"{pair['class1']} - {pair['class2']}: {pair['similarity']:.3f}\")\n",
    "    \n",
    "    return relationship_data\n",
    "\n",
    "relationship_data = class_relationship_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f58a8",
   "metadata": {},
   "source": [
    "### **6. Data Quality Assessment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Data Quality Assessment\n",
    "def data_quality_assessment():\n",
    "    # Check for outliers using z-score\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    mean_intensity = np.mean(X_train_flat, axis=1)\n",
    "    z_scores = (mean_intensity - np.mean(mean_intensity)) / np.std(mean_intensity)\n",
    "    \n",
    "    outlier_indices = np.where(np.abs(z_scores) > 3)[0]\n",
    "    \n",
    "    # Plot potential outliers\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.ravel()\n",
    "    for i, idx in enumerate(outlier_indices[:10]):\n",
    "        axes[i].imshow(X_train[idx], cmap='gray')\n",
    "        axes[i].set_title(f'Potential Outlier\\n{class_names[y_train[idx]]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/06_potential_outliers.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Check data consistency\n",
    "    quality_data = {\n",
    "        'outlier_count': len(outlier_indices),\n",
    "        'outlier_percentage': float(len(outlier_indices) / len(X_train) * 100),\n",
    "        'data_range': {\n",
    "            'min': float(np.min(X_train)),\n",
    "            'max': float(np.max(X_train))\n",
    "        },\n",
    "        'null_values': bool(np.isnan(X_train).any()),\n",
    "        'data_type': str(X_train.dtype)\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/06_data_quality_assessment.json', 'w') as f:\n",
    "        json.dump(quality_data, f, indent=4)\n",
    "    \n",
    "    # Display quality summary\n",
    "    print(\"\\nData Quality Assessment:\")\n",
    "    print(f\"Outlier count: {quality_data['outlier_count']}\")\n",
    "    print(f\"Outlier percentage: {quality_data['outlier_percentage']:.2f}%\")\n",
    "    print(f\"Data range: [{quality_data['data_range']['min']}, {quality_data['data_range']['max']}]\")\n",
    "    print(f\"Contains null values: {quality_data['null_values']}\")\n",
    "    print(f\"Data type: {quality_data['data_type']}\")\n",
    "    \n",
    "    return quality_data\n",
    "\n",
    "quality_data = data_quality_assessment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e39fb",
   "metadata": {},
   "source": [
    "### **7. Preprocessing Insights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Preprocessing Insights\n",
    "def preprocessing_insights():\n",
    "    # Compare normalization techniques\n",
    "    sample_image = X_train[0]\n",
    "    \n",
    "    # Different normalization methods\n",
    "    normalizations = {\n",
    "        'Original': sample_image,\n",
    "        'Min-Max [0,1]': sample_image / 255.0,\n",
    "        'Mean Normalization': (sample_image - np.mean(sample_image)) / np.std(sample_image),\n",
    "        'Standard Scaling': (sample_image - np.mean(X_train)) / np.std(X_train)\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, (name, img) in enumerate(normalizations.items()):\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # Add statistics\n",
    "        axes[i].text(0.5, -0.1, f'Range: [{img.min():.2f}, {img.max():.2f}]', \n",
    "                    ha='center', transform=axes[i].transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/07_normalization_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Analyze brightness and contrast effects\n",
    "    augmentation_examples = {\n",
    "        'Original': sample_image,\n",
    "        'Brightness +50': np.clip(sample_image + 50, 0, 255),\n",
    "        'Brightness -50': np.clip(sample_image - 50, 0, 255),\n",
    "        'Contrast x1.5': np.clip(sample_image * 1.5, 0, 255)\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, (name, img) in enumerate(augmentation_examples.items()):\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/07_augmentation_examples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    preprocessing_recommendations = {\n",
    "        'recommended_normalization': 'Min-Max [0,1]',\n",
    "        'reason': 'Maintains relative pixel intensities while scaling to standard range',\n",
    "        'augmentation_suggestions': [\n",
    "            'Random rotation (±10 degrees)',\n",
    "            'Random horizontal flip',\n",
    "            'Random brightness adjustment (±10%)',\n",
    "            'Random zoom (0.9-1.1x)'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/07_preprocessing_insights.json', 'w') as f:\n",
    "        json.dump(preprocessing_recommendations, f, indent=4)\n",
    "    \n",
    "    # Display recommendations\n",
    "    print(\"\\nPreprocessing Recommendations:\")\n",
    "    print(f\"Normalization: {preprocessing_recommendations['recommended_normalization']}\")\n",
    "    print(f\"Reason: {preprocessing_recommendations['reason']}\")\n",
    "    print(\"\\nSuggested Augmentations:\")\n",
    "    for aug in preprocessing_recommendations['augmentation_suggestions']:\n",
    "        print(f\"- {aug}\")\n",
    "    \n",
    "    return preprocessing_recommendations\n",
    "\n",
    "preprocessing_data = preprocessing_insights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa0220",
   "metadata": {},
   "source": [
    "### **8. Performance Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c235461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Performance Predictions\n",
    "def performance_predictions():\n",
    "    # Based on analysis, predict difficulty of classification\n",
    "    class_difficulty = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        class_images = X_train[y_train == i]\n",
    "        \n",
    "        # Calculate intra-class variance\n",
    "        variance = np.mean(np.var(class_images, axis=0))\n",
    "        \n",
    "        # Get similarity to other classes\n",
    "        similar_classes = []\n",
    "        for j in range(10):\n",
    "            if i != j:\n",
    "                similarity = relationship_data['similarity_matrix'][i][j]\n",
    "                similar_classes.append((class_names[j], similarity))\n",
    "        \n",
    "        similar_classes.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        class_difficulty.append({\n",
    "            'class': class_names[i],\n",
    "            'variance': float(variance),\n",
    "            'most_similar_to': similar_classes[0][0],\n",
    "            'similarity_score': float(similar_classes[0][1])\n",
    "        })\n",
    "    \n",
    "    # Sort by difficulty (higher variance and similarity = more difficult)\n",
    "    class_difficulty.sort(key=lambda x: x['variance'] * x['similarity_score'], reverse=True)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    classes = [item['class'] for item in class_difficulty]\n",
    "    difficulty_scores = [item['variance'] * item['similarity_score'] for item in class_difficulty]\n",
    "    \n",
    "    bars = ax.bar(classes, difficulty_scores)\n",
    "    ax.set_ylabel('Difficulty Score')\n",
    "    ax.set_title('Predicted Classification Difficulty by Class')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Color bars based on difficulty\n",
    "    for bar, score in zip(bars, difficulty_scores):\n",
    "        if score > np.mean(difficulty_scores):\n",
    "            bar.set_color('red')\n",
    "        else:\n",
    "            bar.set_color('green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/08_classification_difficulty_prediction.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    performance_data = {\n",
    "        'class_difficulty_ranking': class_difficulty,\n",
    "        'expected_confusion_pairs': [\n",
    "            {'pair': [item['class'], item['most_similar_to']], \n",
    "             'similarity': item['similarity_score']} \n",
    "            for item in class_difficulty[:5]\n",
    "        ],\n",
    "        'estimated_accuracy_range': {\n",
    "            'simple_model': '85-90%',\n",
    "            'complex_model': '92-95%',\n",
    "            'ensemble': '94-97%'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/08_performance_predictions.json', 'w') as f:\n",
    "        json.dump(performance_data, f, indent=4)\n",
    "    \n",
    "    # Display difficulty ranking\n",
    "    print(\"\\nPredicted Class Difficulty (most to least difficult):\")\n",
    "    for i, item in enumerate(class_difficulty):\n",
    "        print(f\"{i+1}. {item['class']} (Difficulty Score: {item['variance'] * item['similarity_score']:.2f})\")\n",
    "        print(f\"   Most similar to: {item['most_similar_to']} (Similarity: {item['similarity_score']:.3f})\")\n",
    "    \n",
    "    return performance_data\n",
    "\n",
    "performance_data = performance_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dcf3e3",
   "metadata": {},
   "source": [
    "### **9. Comparative Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad84e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Comparative Analysis with Original MNIST\n",
    "def comparative_analysis():\n",
    "    # Load original MNIST for comparison\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "    (mnist_train, _), _ = mnist.load_data()\n",
    "    \n",
    "    # Compare complexity\n",
    "    fashion_complexity = np.mean(np.std(X_train, axis=(1, 2)))\n",
    "    mnist_complexity = np.mean(np.std(mnist_train, axis=(1, 2)))\n",
    "    \n",
    "    # Compare edge density\n",
    "    fashion_edges = np.mean([np.mean(cv2.Canny(img, 100, 200) > 0) for img in X_train[:1000]])\n",
    "    mnist_edges = np.mean([np.mean(cv2.Canny(img, 100, 200) > 0) for img in mnist_train[:1000]])\n",
    "    \n",
    "    # Visual comparison\n",
    "    fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    \n",
    "    for i in range(10):\n",
    "        axes[0, i].imshow(X_train[i], cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, 0].set_ylabel('Fashion\\nMNIST', rotation=0, labelpad=40)\n",
    "        \n",
    "        axes[1, i].imshow(mnist_train[i], cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, 0].set_ylabel('Original\\nMNIST', rotation=0, labelpad=40)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/09_mnist_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Create comparison bar chart\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Complexity comparison\n",
    "    ax1.bar(['Fashion MNIST', 'Original MNIST'], [fashion_complexity, mnist_complexity])\n",
    "    ax1.set_ylabel('Complexity Score')\n",
    "    ax1.set_title('Complexity Comparison')\n",
    "    \n",
    "    # Edge density comparison\n",
    "    ax2.bar(['Fashion MNIST', 'Original MNIST'], [fashion_edges, mnist_edges])\n",
    "    ax2.set_ylabel('Edge Density')\n",
    "    ax2.set_title('Edge Density Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/09_complexity_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    comparison_data = {\n",
    "        'complexity_comparison': {\n",
    "            'fashion_mnist': float(fashion_complexity),\n",
    "            'original_mnist': float(mnist_complexity),\n",
    "            'complexity_ratio': float(fashion_complexity / mnist_complexity)\n",
    "        },\n",
    "        'edge_density_comparison': {\n",
    "            'fashion_mnist': float(fashion_edges),\n",
    "            'original_mnist': float(mnist_edges),\n",
    "            'edge_ratio': float(fashion_edges / mnist_edges)\n",
    "        },\n",
    "        'key_differences': [\n",
    "            'Fashion MNIST has more complex patterns and textures',\n",
    "            'Higher intra-class variability in Fashion MNIST',\n",
    "            'More challenging due to visual similarity between classes',\n",
    "            'Requires more sophisticated feature extraction'\n",
    "        ],\n",
    "        'architecture_recommendations': [\n",
    "            'Use deeper CNNs for Fashion MNIST',\n",
    "            'Consider attention mechanisms',\n",
    "            'Implement data augmentation',\n",
    "            'Use ensemble methods for best performance'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/09_comparative_analysis.json', 'w') as f:\n",
    "        json.dump(comparison_data, f, indent=4)\n",
    "    \n",
    "    # Display comparison summary\n",
    "    print(\"\\nComparative Analysis:\")\n",
    "    print(f\"Fashion MNIST is {comparison_data['complexity_comparison']['complexity_ratio']:.2f}x more complex\")\n",
    "    print(f\"Fashion MNIST has {comparison_data['edge_density_comparison']['edge_ratio']:.2f}x edge density\")\n",
    "    print(\"\\nKey differences:\")\n",
    "    for diff in comparison_data['key_differences']:\n",
    "        print(f\"- {diff}\")\n",
    "    \n",
    "    return comparison_data\n",
    "\n",
    "comparison_data = comparative_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd3038",
   "metadata": {},
   "source": [
    "### **Executive Summary Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed712a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Executive Summary\n",
    "def generate_executive_summary():\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    summary = {\n",
    "        'analysis_timestamp': timestamp,\n",
    "        'dataset_summary': {\n",
    "            'total_samples': overview_data['total_train_samples'] + overview_data['total_test_samples'],\n",
    "            'image_dimensions': overview_data['image_shape'],\n",
    "            'number_of_classes': 10,\n",
    "            'class_balance': 'Balanced (6,000 samples per class)'\n",
    "        },\n",
    "        'key_findings': {\n",
    "            'data_quality': f\"{quality_data['outlier_percentage']:.2f}% potential outliers detected\",\n",
    "            'dimensionality': f\"{dim_data['pca_components_needed_95']} components explain 95% variance\",\n",
    "            'class_relationships': f\"Most similar classes: {relationship_data['most_similar_pairs'][0]['class1']} and {relationship_data['most_similar_pairs'][0]['class2']}\",\n",
    "            'complexity': f\"{comparison_data['complexity_comparison']['complexity_ratio']:.2f}x more complex than original MNIST\"\n",
    "        },\n",
    "        'recommendations': {\n",
    "            'preprocessing': preprocessing_data['recommended_normalization'],\n",
    "            'architecture': comparison_data['architecture_recommendations'][0],\n",
    "            'expected_performance': performance_data['estimated_accuracy_range']['complex_model']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('./analysis_results/10_executive_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=4)\n",
    "    \n",
    "    # Create a visual summary\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Class distribution\n",
    "    train_dist = np.bincount(y_train)\n",
    "    ax1.bar(class_names, train_dist)\n",
    "    ax1.set_title('Class Distribution')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # PCA variance\n",
    "    pca_variance = dim_data['pca_explained_variance_ratio'][:20]\n",
    "    ax2.plot(range(1, 21), np.cumsum(pca_variance))\n",
    "    ax2.set_title('PCA Explained Variance')\n",
    "    ax2.set_xlabel('Components')\n",
    "    ax2.set_ylabel('Cumulative Variance')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Class similarity\n",
    "    im = ax3.imshow(relationship_data['similarity_matrix'], cmap='coolwarm')\n",
    "    ax3.set_xticks(range(10))\n",
    "    ax3.set_yticks(range(10))\n",
    "    ax3.set_xticklabels(class_names, rotation=45)\n",
    "    ax3.set_yticklabels(class_names)\n",
    "    ax3.set_title('Class Similarity Matrix')\n",
    "    plt.colorbar(im, ax=ax3)\n",
    "    \n",
    "    # Difficulty prediction\n",
    "    classes = [item['class'] for item in performance_data['class_difficulty_ranking']][:5]\n",
    "    scores = [item['variance'] * item['similarity_score'] for item in performance_data['class_difficulty_ranking']][:5]\n",
    "    ax4.bar(classes, scores)\n",
    "    ax4.set_title('Top 5 Most Difficult Classes')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./analysis_results/10_executive_summary_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()  # Display in notebook\n",
    "    \n",
    "    # Display key findings\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXECUTIVE SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nAnalysis Timestamp: {timestamp}\")\n",
    "    \n",
    "    print(\"\\nDataset Summary:\")\n",
    "    print(f\"- Total samples: {summary['dataset_summary']['total_samples']}\")\n",
    "    print(f\"- Image dimensions: {summary['dataset_summary']['image_dimensions']}\")\n",
    "    print(f\"- Number of classes: {summary['dataset_summary']['number_of_classes']}\")\n",
    "    print(f\"- Class balance: {summary['dataset_summary']['class_balance']}\")\n",
    "   \n",
    "    print(\"\\nKey Findings:\")\n",
    "    for key, value in summary['key_findings'].items():\n",
    "        print(f\"- {key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    print(\"\\nRecommendations:\")\n",
    "    for key, value in summary['recommendations'].items():\n",
    "        print(f\"- {key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "executive_summary = generate_executive_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab5e44",
   "metadata": {},
   "source": [
    "### **Additional Visualization for Executive Summary (Dashboard)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive dashboard-style summary\n",
    "def create_dashboard_summary():\n",
    "    # Create a large figure with multiple subplots\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Class Distribution\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    train_dist = np.bincount(y_train)\n",
    "    ax1.bar(class_names, train_dist, color='skyblue')\n",
    "    ax1.set_title('Class Distribution', fontsize=16)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    # 2. Sample Images\n",
    "    ax2 = fig.add_subplot(gs[0, 1:])\n",
    "    for i in range(10):\n",
    "        ax2_sub = ax2.inset_axes([(i/10), 0, 0.09, 1])\n",
    "        ax2_sub.imshow(X_train[y_train == i][0], cmap='gray')\n",
    "        ax2_sub.axis('off')\n",
    "        ax2_sub.set_title(class_names[i], fontsize=10)\n",
    "    ax2.set_title('Sample Images by Class', fontsize=16)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # 3. PCA Analysis\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    pca_variance = dim_data['pca_explained_variance_ratio'][:20]\n",
    "    ax3.plot(range(1, 21), np.cumsum(pca_variance), 'o-')\n",
    "    ax3.set_xlabel('Components')\n",
    "    ax3.set_ylabel('Cumulative Variance')\n",
    "    ax3.set_title('PCA Analysis', fontsize=16)\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # 4. Class Similarity\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    im = ax4.imshow(relationship_data['similarity_matrix'], cmap='coolwarm')\n",
    "    ax4.set_xticks(range(10))\n",
    "    ax4.set_yticks(range(10))\n",
    "    ax4.set_xticklabels(class_names, rotation=45)\n",
    "    ax4.set_yticklabels(class_names)\n",
    "    ax4.set_title('Class Similarity Matrix', fontsize=16)\n",
    "    plt.colorbar(im, ax=ax4)\n",
    "    \n",
    "    # 5. Difficulty Prediction\n",
    "    ax5 = fig.add_subplot(gs[1, 2])\n",
    "    classes = [item['class'] for item in performance_data['class_difficulty_ranking']]\n",
    "    scores = [item['variance'] * item['similarity_score'] for item in performance_data['class_difficulty_ranking']]\n",
    "    bars = ax5.barh(classes, scores, color='coral')\n",
    "    ax5.set_xlabel('Difficulty Score')\n",
    "    ax5.set_title('Classification Difficulty', fontsize=16)\n",
    "    ax5.invert_yaxis()\n",
    "    \n",
    "    # 6. Complexity Comparison\n",
    "    ax6 = fig.add_subplot(gs[2, 0])\n",
    "    comparison_metrics = ['Complexity', 'Edge Density']\n",
    "    fashion_values = [\n",
    "        comparison_data['complexity_comparison']['fashion_mnist'],\n",
    "        comparison_data['edge_density_comparison']['fashion_mnist']\n",
    "    ]\n",
    "    mnist_values = [\n",
    "        comparison_data['complexity_comparison']['original_mnist'],\n",
    "        comparison_data['edge_density_comparison']['original_mnist']\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(comparison_metrics))\n",
    "    width = 0.35\n",
    "    ax6.bar(x - width/2, fashion_values, width, label='Fashion MNIST', color='steelblue')\n",
    "    ax6.bar(x + width/2, mnist_values, width, label='Original MNIST', color='lightcoral')\n",
    "    ax6.set_xticks(x)\n",
    "    ax6.set_xticklabels(comparison_metrics)\n",
    "    ax6.set_ylabel('Value')\n",
    "    ax6.set_title('Comparison with Original MNIST', fontsize=16)\n",
    "    ax6.legend()\n",
    "    \n",
    "    # 7. Data Quality Metrics\n",
    "    ax7 = fig.add_subplot(gs[2, 1:])\n",
    "    quality_metrics = {\n",
    "        'Total Samples': overview_data['total_train_samples'] + overview_data['total_test_samples'],\n",
    "        'Outliers': quality_data['outlier_count'],\n",
    "        'Outlier %': quality_data['outlier_percentage'],\n",
    "        'Min Pixel': quality_data['data_range']['min'],\n",
    "        'Max Pixel': quality_data['data_range']['max'],\n",
    "        'PCA Components (95%)': dim_data['pca_components_needed_95']\n",
    "    }\n",
    "    \n",
    "    # Create a text table\n",
    "    cell_text = [[key, f\"{value:.2f}\" if isinstance(value, float) else str(value)] \n",
    "                 for key, value in quality_metrics.items()]\n",
    "    table = ax7.table(cellText=cell_text, colLabels=['Metric', 'Value'], \n",
    "                      cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.5)\n",
    "    ax7.axis('off')\n",
    "    ax7.set_title('Summary Statistics', fontsize=16)\n",
    "    \n",
    "    plt.suptitle('Fashion MNIST Dataset Analysis Dashboard', fontsize=24, y=0.98)\n",
    "    plt.savefig('./analysis_results/11_analysis_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Create the dashboard summary\n",
    "create_dashboard_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ae4eb",
   "metadata": {},
   "source": [
    "### **Run all analyses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_analysis():\n",
    "    print(\"Starting Fashion MNIST Analysis...\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\"1. Dataset Overview...\")\n",
    "    print(\"-\"*30)\n",
    "    global overview_data\n",
    "    overview_data = analyze_dataset_overview()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"2. Statistical Analysis...\")\n",
    "    print(\"-\"*30)\n",
    "    global stats_data\n",
    "    stats_data = statistical_analysis()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"3. Visual Pattern Analysis...\")\n",
    "    print(\"-\"*30)\n",
    "    global average_images\n",
    "    average_images = visual_pattern_analysis()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"4. Dimensionality Analysis...\")\n",
    "    print(\"-\"*30)\n",
    "    global dim_data\n",
    "    dim_data = dimensionality_analysis()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"5. Class Relationship Analysis...\")\n",
    "    print(\"-\"*30)\n",
    "    global relationship_data\n",
    "    relationship_data = class_relationship_analysis()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"6. Data Quality Assessment...\")\n",
    "    print(\"-\"*30)\n",
    "    global quality_data\n",
    "    quality_data = data_quality_assessment()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"7. Preprocessing Insights...\")\n",
    "    print(\"-\"*30)\n",
    "    global preprocessing_data\n",
    "    preprocessing_data = preprocessing_insights()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"8. Performance Predictions...\")\n",
    "    print(\"-\"*30)\n",
    "    global performance_data\n",
    "    performance_data = performance_predictions()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"9. Comparative Analysis...\")\n",
    "    print(\"-\"*30)\n",
    "    global comparison_data\n",
    "    comparison_data = comparative_analysis()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"10. Generating Executive Summary...\")\n",
    "    print(\"-\"*30)\n",
    "    global executive_summary\n",
    "    executive_summary = generate_executive_summary()\n",
    "    \n",
    "    print(\"\\n11. Creating Dashboard Summary...\")\n",
    "    print(\"-\"*30)\n",
    "    create_dashboard_summary()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Analysis Complete! Check ./analysis_results/ for all outputs.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Run the complete analysis\n",
    "if __name__ == \"__main__\":\n",
    "    run_complete_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f3261",
   "metadata": {},
   "source": [
    "### **Display all JSON files as formatted tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45774d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 01_dataset_overview.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>T-shirt/top</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Trouser</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Pullover</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Dress</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Coat</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Sandal</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Sneaker</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Bag</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_distribution</td>\n",
       "      <td>Ankle boot</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>T-shirt/top</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Trouser</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Pullover</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Dress</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Coat</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Sandal</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Sneaker</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Bag</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_distribution</td>\n",
       "      <td>Ankle boot</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>image_shape</td>\n",
       "      <td>[28, 28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>total_train_samples</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>total_test_samples</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Category               Metric        Value\n",
       "0   train_distribution          T-shirt/top         6000\n",
       "1   train_distribution              Trouser         6000\n",
       "2   train_distribution             Pullover         6000\n",
       "3   train_distribution                Dress         6000\n",
       "4   train_distribution                 Coat         6000\n",
       "5   train_distribution               Sandal         6000\n",
       "6   train_distribution                Shirt         6000\n",
       "7   train_distribution              Sneaker         6000\n",
       "8   train_distribution                  Bag         6000\n",
       "9   train_distribution           Ankle boot         6000\n",
       "10   test_distribution          T-shirt/top         1000\n",
       "11   test_distribution              Trouser         1000\n",
       "12   test_distribution             Pullover         1000\n",
       "13   test_distribution                Dress         1000\n",
       "14   test_distribution                 Coat         1000\n",
       "15   test_distribution               Sandal         1000\n",
       "16   test_distribution                Shirt         1000\n",
       "17   test_distribution              Sneaker         1000\n",
       "18   test_distribution                  Bag         1000\n",
       "19   test_distribution           Ankle boot         1000\n",
       "20                              image_shape  [28, 28]...\n",
       "21                      total_train_samples        60000\n",
       "22                       total_test_samples        10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 02_statistical_analysis.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_statistics</td>\n",
       "      <td>mean</td>\n",
       "      <td>72.940352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global_statistics</td>\n",
       "      <td>std</td>\n",
       "      <td>90.021182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>T-shirt/top</td>\n",
       "      <td>{'mean': 83.02998044217686, 'std': 89.43848028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Trouser</td>\n",
       "      <td>{'mean': 56.84085522959184, 'std': 87.60026328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Pullover</td>\n",
       "      <td>{'mean': 96.058762542517, 'std': 91.4634663691...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Dress</td>\n",
       "      <td>{'mean': 66.01890858843538, 'std': 90.32600060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Coat</td>\n",
       "      <td>{'mean': 98.25800552721088, 'std': 95.95952360...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Sandal</td>\n",
       "      <td>{'mean': 34.86754655612245, 'std': 67.09256263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>{'mean': 84.60511989795918, 'std': 86.51605067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Sneaker</td>\n",
       "      <td>{'mean': 42.76207227891157, 'std': 75.17057254...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Bag</td>\n",
       "      <td>{'mean': 90.15715284863946, 'std': 93.14415008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>class_statistics</td>\n",
       "      <td>Ankle boot</td>\n",
       "      <td>{'mean': 76.80511840986395, 'std': 94.48588327...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Category       Metric  \\\n",
       "0   global_statistics         mean   \n",
       "1   global_statistics          std   \n",
       "2    class_statistics  T-shirt/top   \n",
       "3    class_statistics      Trouser   \n",
       "4    class_statistics     Pullover   \n",
       "5    class_statistics        Dress   \n",
       "6    class_statistics         Coat   \n",
       "7    class_statistics       Sandal   \n",
       "8    class_statistics        Shirt   \n",
       "9    class_statistics      Sneaker   \n",
       "10   class_statistics          Bag   \n",
       "11   class_statistics   Ankle boot   \n",
       "\n",
       "                                                Value  \n",
       "0                                           72.940352  \n",
       "1                                           90.021182  \n",
       "2   {'mean': 83.02998044217686, 'std': 89.43848028...  \n",
       "3   {'mean': 56.84085522959184, 'std': 87.60026328...  \n",
       "4   {'mean': 96.058762542517, 'std': 91.4634663691...  \n",
       "5   {'mean': 66.01890858843538, 'std': 90.32600060...  \n",
       "6   {'mean': 98.25800552721088, 'std': 95.95952360...  \n",
       "7   {'mean': 34.86754655612245, 'std': 67.09256263...  \n",
       "8   {'mean': 84.60511989795918, 'std': 86.51605067...  \n",
       "9   {'mean': 42.76207227891157, 'std': 75.17057254...  \n",
       "10  {'mean': 90.15715284863946, 'std': 93.14415008...  \n",
       "11  {'mean': 76.80511840986395, 'std': 94.48588327...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 04_dimensionality_analysis.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>pca_explained_variance_ratio</td>\n",
       "      <td>[0.2903922792136605, 0.17755309978162206, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>pca_components_needed_95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                        Metric  \\\n",
       "0           pca_explained_variance_ratio   \n",
       "1               pca_components_needed_95   \n",
       "\n",
       "                                               Value  \n",
       "0  [0.2903922792136605, 0.17755309978162206, 0.06...  \n",
       "1                                                  1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 05_class_relationships.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>similarity_matrix</td>\n",
       "      <td>[[1.0000000000000004, 0.8366765717192833, 0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>most_similar_pairs</td>\n",
       "      <td>[{'class1': 'Coat', 'class2': 'Shirt', 'simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>least_similar_pairs</td>\n",
       "      <td>[{'class1': 'Trouser', 'class2': 'Ankle boot',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category               Metric  \\\n",
       "0             similarity_matrix   \n",
       "1            most_similar_pairs   \n",
       "2           least_similar_pairs   \n",
       "\n",
       "                                               Value  \n",
       "0  [[1.0000000000000004, 0.8366765717192833, 0.89...  \n",
       "1  [{'class1': 'Coat', 'class2': 'Shirt', 'simila...  \n",
       "2  [{'class1': 'Trouser', 'class2': 'Ankle boot',...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 06_data_quality_assessment.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>outlier_count</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>outlier_percentage</td>\n",
       "      <td>0.061667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_range</td>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_range</td>\n",
       "      <td>max</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>null_values</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>data_type</td>\n",
       "      <td>uint8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category              Metric     Value\n",
       "0                   outlier_count        37\n",
       "1              outlier_percentage  0.061667\n",
       "2  data_range                 min       0.0\n",
       "3  data_range                 max     255.0\n",
       "4                     null_values     False\n",
       "5                       data_type     uint8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 07_preprocessing_insights.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>recommended_normalization</td>\n",
       "      <td>Min-Max [0,1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>reason</td>\n",
       "      <td>Maintains relative pixel intensities while sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>augmentation_suggestions</td>\n",
       "      <td>['Random rotation (±10 degrees)', 'Random hori...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                     Metric  \\\n",
       "0           recommended_normalization   \n",
       "1                              reason   \n",
       "2            augmentation_suggestions   \n",
       "\n",
       "                                               Value  \n",
       "0                                      Min-Max [0,1]  \n",
       "1  Maintains relative pixel intensities while sca...  \n",
       "2  ['Random rotation (±10 degrees)', 'Random hori...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 08_performance_predictions.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>class_difficulty_ranking</td>\n",
       "      <td>[{'class': 'Bag', 'variance': 5172.82532960208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>expected_confusion_pairs</td>\n",
       "      <td>[{'pair': ['Bag', 'Coat'], 'similarity': 0.893...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>estimated_accuracy_range</td>\n",
       "      <td>simple_model</td>\n",
       "      <td>85-90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>estimated_accuracy_range</td>\n",
       "      <td>complex_model</td>\n",
       "      <td>92-95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estimated_accuracy_range</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>94-97%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Category                    Metric  \\\n",
       "0                            class_difficulty_ranking   \n",
       "1                            expected_confusion_pairs   \n",
       "2  estimated_accuracy_range              simple_model   \n",
       "3  estimated_accuracy_range             complex_model   \n",
       "4  estimated_accuracy_range                  ensemble   \n",
       "\n",
       "                                               Value  \n",
       "0  [{'class': 'Bag', 'variance': 5172.82532960208...  \n",
       "1  [{'pair': ['Bag', 'Coat'], 'similarity': 0.893...  \n",
       "2                                             85-90%  \n",
       "3                                             92-95%  \n",
       "4                                             94-97%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 09_comparative_analysis.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complexity_comparison</td>\n",
       "      <td>fashion_mnist</td>\n",
       "      <td>81.663476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complexity_comparison</td>\n",
       "      <td>original_mnist</td>\n",
       "      <td>76.834539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complexity_comparison</td>\n",
       "      <td>complexity_ratio</td>\n",
       "      <td>1.062849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edge_density_comparison</td>\n",
       "      <td>fashion_mnist</td>\n",
       "      <td>0.160958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edge_density_comparison</td>\n",
       "      <td>original_mnist</td>\n",
       "      <td>0.108818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>edge_density_comparison</td>\n",
       "      <td>edge_ratio</td>\n",
       "      <td>1.479153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>key_differences</td>\n",
       "      <td>['Fashion MNIST has more complex patterns and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>architecture_recommendations</td>\n",
       "      <td>['Use deeper CNNs for Fashion MNIST', 'Conside...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Category                        Metric  \\\n",
       "0    complexity_comparison                 fashion_mnist   \n",
       "1    complexity_comparison                original_mnist   \n",
       "2    complexity_comparison              complexity_ratio   \n",
       "3  edge_density_comparison                 fashion_mnist   \n",
       "4  edge_density_comparison                original_mnist   \n",
       "5  edge_density_comparison                    edge_ratio   \n",
       "6                                        key_differences   \n",
       "7                           architecture_recommendations   \n",
       "\n",
       "                                               Value  \n",
       "0                                          81.663476  \n",
       "1                                          76.834539  \n",
       "2                                           1.062849  \n",
       "3                                           0.160958  \n",
       "4                                           0.108818  \n",
       "5                                           1.479153  \n",
       "6  ['Fashion MNIST has more complex patterns and ...  \n",
       "7  ['Use deeper CNNs for Fashion MNIST', 'Conside...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Contents of: 10_executive_summary.json\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>analysis_timestamp</td>\n",
       "      <td>2025-04-27 11:05:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset_summary</td>\n",
       "      <td>total_samples</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset_summary</td>\n",
       "      <td>image_dimensions</td>\n",
       "      <td>[28, 28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset_summary</td>\n",
       "      <td>number_of_classes</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset_summary</td>\n",
       "      <td>class_balance</td>\n",
       "      <td>Balanced (6,000 samples per class)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>key_findings</td>\n",
       "      <td>data_quality</td>\n",
       "      <td>0.06% potential outliers detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>key_findings</td>\n",
       "      <td>dimensionality</td>\n",
       "      <td>1 components explain 95% variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>key_findings</td>\n",
       "      <td>class_relationships</td>\n",
       "      <td>Most similar classes: Coat and Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>key_findings</td>\n",
       "      <td>complexity</td>\n",
       "      <td>1.06x more complex than original MNIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>recommendations</td>\n",
       "      <td>preprocessing</td>\n",
       "      <td>Min-Max [0,1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>recommendations</td>\n",
       "      <td>architecture</td>\n",
       "      <td>Use deeper CNNs for Fashion MNIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>recommendations</td>\n",
       "      <td>expected_performance</td>\n",
       "      <td>92-95%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category                Metric  \\\n",
       "0                      analysis_timestamp   \n",
       "1   dataset_summary         total_samples   \n",
       "2   dataset_summary      image_dimensions   \n",
       "3   dataset_summary     number_of_classes   \n",
       "4   dataset_summary         class_balance   \n",
       "5      key_findings          data_quality   \n",
       "6      key_findings        dimensionality   \n",
       "7      key_findings   class_relationships   \n",
       "8      key_findings            complexity   \n",
       "9   recommendations         preprocessing   \n",
       "10  recommendations          architecture   \n",
       "11  recommendations  expected_performance   \n",
       "\n",
       "                                     Value  \n",
       "0                      2025-04-27 11:05:20  \n",
       "1                                    70000  \n",
       "2                              [28, 28]...  \n",
       "3                                       10  \n",
       "4       Balanced (6,000 samples per class)  \n",
       "5        0.06% potential outliers detected  \n",
       "6        1 components explain 95% variance  \n",
       "7     Most similar classes: Coat and Shirt  \n",
       "8   1.06x more complex than original MNIST  \n",
       "9                            Min-Max [0,1]  \n",
       "10       Use deeper CNNs for Fashion MNIST  \n",
       "11                                  92-95%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_json_files():\n",
    "    \"\"\"Display all JSON files in the analysis_results directory as formatted tables.\"\"\"\n",
    "    import glob\n",
    "    \n",
    "    json_files = sorted(glob.glob('./analysis_results/*.json'))\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(f\"Contents of: {os.path.basename(json_file)}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            # For nested dictionaries, create a flattened view\n",
    "            rows = []\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for sub_key, sub_value in value.items():\n",
    "                        rows.append({\n",
    "                            'Category': key,\n",
    "                            'Metric': sub_key,\n",
    "                            'Value': sub_value if not isinstance(sub_value, (list, dict)) else str(sub_value)[:50] + '...'\n",
    "                        })\n",
    "                else:\n",
    "                    rows.append({\n",
    "                        'Category': '',\n",
    "                        'Metric': key,\n",
    "                        'Value': value if not isinstance(value, (list, dict)) else str(value)[:50] + '...'\n",
    "                    })\n",
    "            \n",
    "            df = pd.DataFrame(rows)\n",
    "            display(df)\n",
    "        else:\n",
    "            print(data)\n",
    "\n",
    "# Display all JSON files as formatted tables\n",
    "display_json_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d3e4eb",
   "metadata": {},
   "source": [
    "### **Create a summary of all generated files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24926029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GENERATED FILES SUMMARY\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_class_distribution.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>175.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_dataset_overview.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_class_brightness_distribution.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>218.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02_pixel_intensity_distribution.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>64.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02_statistical_analysis.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>03_average_class_images.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03_class_samples.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>250.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>03_edge_detection_analysis.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>71.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04_dimensionality_analysis.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>04_pca_explained_variance.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>121.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>04_tsne_visualization.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>2058.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05_class_relationships.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>05_class_similarity_matrix.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>353.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>06_data_quality_assessment.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>06_potential_outliers.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>93.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>07_augmentation_examples.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>75.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>07_normalization_comparison.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>07_preprocessing_insights.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08_classification_difficulty_prediction.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>141.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08_performance_predictions.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>09_comparative_analysis.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>09_complexity_comparison.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>122.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>09_mnist_comparison.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>43.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10_executive_summary.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10_executive_summary_visualization.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>419.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11_analysis_dashboard.png</td>\n",
       "      <td>PNG</td>\n",
       "      <td>735.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Filename  Type  Size (KB)\n",
       "0                     01_class_distribution.png   PNG     175.21\n",
       "1                      01_dataset_overview.json  JSON       0.66\n",
       "2          02_class_brightness_distribution.png   PNG     218.85\n",
       "3           02_pixel_intensity_distribution.png   PNG      64.75\n",
       "4                  02_statistical_analysis.json  JSON       1.94\n",
       "5                   03_average_class_images.png   PNG      99.74\n",
       "6                          03_class_samples.png   PNG     250.63\n",
       "7                03_edge_detection_analysis.png   PNG      71.16\n",
       "8               04_dimensionality_analysis.json  JSON       1.55\n",
       "9                 04_pca_explained_variance.png   PNG     121.63\n",
       "10                    04_tsne_visualization.png   PNG    2058.52\n",
       "11                  05_class_relationships.json  JSON       4.70\n",
       "12               05_class_similarity_matrix.png   PNG     353.38\n",
       "13              06_data_quality_assessment.json  JSON       0.19\n",
       "14                    06_potential_outliers.png   PNG      93.50\n",
       "15                 07_augmentation_examples.png   PNG      75.36\n",
       "16              07_normalization_comparison.png   PNG      99.13\n",
       "17               07_preprocessing_insights.json  JSON       0.34\n",
       "18  08_classification_difficulty_prediction.png   PNG     141.67\n",
       "19              08_performance_predictions.json  JSON       2.79\n",
       "20                 09_comparative_analysis.json  JSON       0.83\n",
       "21                 09_complexity_comparison.png   PNG     122.74\n",
       "22                      09_mnist_comparison.png   PNG      43.36\n",
       "23                    10_executive_summary.json  JSON       0.73\n",
       "24       10_executive_summary_visualization.png   PNG     419.59\n",
       "25                    11_analysis_dashboard.png   PNG     735.41"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_file_summary():\n",
    "    \"\"\"Create a summary of all generated files.\"\"\"\n",
    "    import glob\n",
    "    \n",
    "    all_files = sorted(glob.glob('./analysis_results/*'))\n",
    "    \n",
    "    file_summary = pd.DataFrame({\n",
    "        'Filename': [os.path.basename(f) for f in all_files],\n",
    "        'Type': [os.path.splitext(f)[1][1:].upper() for f in all_files],\n",
    "        'Size (KB)': [os.path.getsize(f) / 1024 for f in all_files]\n",
    "    })\n",
    "    \n",
    "    file_summary['Size (KB)'] = file_summary['Size (KB)'].round(2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"GENERATED FILES SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    display(file_summary)\n",
    "    \n",
    "    # Save the file summary\n",
    "    file_summary.to_csv('./analysis_results/00_file_summary.csv', index=False)\n",
    "    \n",
    "    return file_summary\n",
    "\n",
    "# Create and display file summary\n",
    "file_summary = create_file_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557393e3",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1714f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow-GPU)",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
